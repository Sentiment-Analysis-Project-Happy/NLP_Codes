{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import theano\n",
    "import numpy\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import cross_validate\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for reproducibility i.e for same results for a given input every time the program is run\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'\n",
    "theano.config.compute_test_value = 'off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset and creating numeric labels as keras only accepts numeric inputs and outputs.\n",
    "positive_examples=list(open('C:\\\\Users\\\\Vineet\\\\Desktop\\\\positive.txt',mode='r',encoding='utf8'))\n",
    "positive_examples = [s.strip() for s in positive_examples]\n",
    "negative_examples=list(open('C:\\\\Users\\\\vineet\\\\Desktop\\\\Negative.txt',mode='r',encoding='utf8'))\n",
    "negative_examples = [s.strip() for s in negative_examples]\n",
    "x=positive_examples+negative_examples\n",
    "#print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727,)\n",
      "(727, 1)\n"
     ]
    }
   ],
   "source": [
    "xa=np.asarray(x)\n",
    "print (xa.shape)\n",
    "positive_labels = [[1] for _ in positive_examples]\n",
    "negative_labels = [[0] for _ in negative_examples]\n",
    "y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "print (y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508,)\n",
      "(219,)\n",
      "(508, 1)\n",
      "(219, 1)\n",
      "भारत के महाकवि कालिदास के हाथों मारे गए थे :\n"
     ]
    }
   ],
   "source": [
    "#using train_test_split to automatically split data into train and test in ratio 70:30 respectively.\n",
    "from sklearn.model_selection import train_test_split\n",
    "xa_train,xa_test,y_train,y_test=train_test_split(xa,y,test_size=0.3,random_state=4)\n",
    "print(xa_train.shape)\n",
    "print(xa_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(xa_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  23    2 1071 1072    2  329  431   81   51    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "5000\n",
      "भारत के महाकवि कालिदास के हाथों मारे गए थे :\n"
     ]
    }
   ],
   "source": [
    "#tokenizer used to split each line into words and then labelling each word with a key(a numeric value) \n",
    "#so as to generate an array to pass in furthur functions using pad_sequences.\n",
    "tokenizer = Tokenizer(num_words=None,split=' ',lower=True)\n",
    "tokenizer.fit_on_texts(xa_train)\n",
    "integer_sentences_train = tokenizer.texts_to_sequences(xa_train)\n",
    "data_train = pad_sequences(integer_sentences_train,padding='post',truncating='post',value=0.)\n",
    "print(data_train[0])\n",
    "top_words = 5000 #len(tokenizer.word_index)\n",
    "print(top_words)\n",
    "max_words = 30\n",
    "print(xa_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  70 3467    8 3468  136 3469 3470 3471   28 3472 3473 3474   19 3475\n",
      "   54 3476 3477  196    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "अपनी कमजोरियोँ का जिक्र कभी नकरना जमाने से। लोग कटी पतंगको जम कर लुटा करते हैँ॥ #MinionsOnStarMovies #KashmirFloods\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(xa_test)\n",
    "integer_sentences_test = tokenizer.texts_to_sequences(xa_test)\n",
    "data_test = pad_sequences(integer_sentences_test,padding='post',truncating='post',value=0.)\n",
    "print(data_test[0])\n",
    "print(xa_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = sequence.pad_sequences(data_train, maxlen=max_words, dtype='float32')\n",
    "data_test = sequence.pad_sequences(data_test, maxlen=max_words, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"tanh\", filters=28, kernel_size=3, padding=\"same\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Vineet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 20)            100000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 28)            1708      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 28)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 15, 100)           12900     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 15, 80)            57920     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                24020     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 196,569\n",
      "Trainable params: 196,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#creating the model i.e adding the layers to the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = top_words, output_dim = 20, input_length=max_words))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=28, filter_length=3, border_mode='same', activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(SimpleRNN(100,return_sequences=True))\n",
    "model.add(LSTM(80,return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 507 samples, validate on 219 samples\n",
      "Epoch 1/5\n",
      "507/507 [==============================] - 0s 963us/step - loss: 0.1969 - accuracy: 0.9290 - val_loss: 0.8941 - val_accuracy: 0.6530\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 0s 934us/step - loss: 0.0650 - accuracy: 0.9803 - val_loss: 1.3355 - val_accuracy: 0.7215\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 0s 876us/step - loss: 0.0462 - accuracy: 0.9882 - val_loss: 1.9228 - val_accuracy: 0.6575\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 0s 930us/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 2.3371 - val_accuracy: 0.6256\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 0s 917us/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 2.0521 - val_accuracy: 0.6530\n",
      "218/218 [==============================] - 0s 415us/step\n",
      "[[3.58537375e-03]\n",
      " [1.33017853e-01]\n",
      " [2.66101386e-04]\n",
      " [9.90972016e-03]\n",
      " [1.04043036e-04]\n",
      " [6.12499595e-01]\n",
      " [1.11515292e-04]\n",
      " [5.92171855e-04]\n",
      " [1.28153088e-05]\n",
      " [9.95210826e-01]\n",
      " [2.22414755e-03]\n",
      " [5.41307636e-05]\n",
      " [9.94985819e-01]\n",
      " [9.24064636e-01]\n",
      " [5.68535971e-03]\n",
      " [1.21380240e-01]\n",
      " [7.18486845e-05]\n",
      " [6.66086257e-01]\n",
      " [9.80501711e-01]\n",
      " [4.95757401e-01]\n",
      " [9.99267958e-03]\n",
      " [9.76977468e-01]\n",
      " [8.63851456e-05]\n",
      " [9.07591220e-06]\n",
      " [2.14527216e-04]\n",
      " [4.26719477e-03]\n",
      " [2.53647522e-05]\n",
      " [9.98239517e-01]\n",
      " [5.44187985e-02]\n",
      " [1.98428315e-04]\n",
      " [1.06874149e-05]\n",
      " [2.60241283e-03]\n",
      " [3.94661166e-03]\n",
      " [4.84770353e-05]\n",
      " [7.95447826e-01]\n",
      " [9.36840479e-06]\n",
      " [1.88401958e-03]\n",
      " [9.97667730e-01]\n",
      " [1.15108211e-03]\n",
      " [9.84213352e-01]\n",
      " [9.40809585e-03]\n",
      " [2.74885169e-05]\n",
      " [1.01544391e-02]\n",
      " [9.88372982e-01]\n",
      " [9.98126328e-01]\n",
      " [3.93957039e-03]\n",
      " [4.71898020e-05]\n",
      " [1.96154768e-04]\n",
      " [1.49981925e-05]\n",
      " [6.32304000e-05]\n",
      " [1.60183663e-05]\n",
      " [2.70425022e-04]\n",
      " [6.75797183e-03]\n",
      " [7.42201865e-01]\n",
      " [9.66465652e-01]\n",
      " [3.49919028e-05]\n",
      " [1.85278026e-04]\n",
      " [9.95006025e-01]\n",
      " [2.64953793e-04]\n",
      " [1.27819148e-05]\n",
      " [1.54522585e-03]\n",
      " [1.80217205e-03]\n",
      " [5.53667778e-05]\n",
      " [1.91045438e-05]\n",
      " [1.02648606e-04]\n",
      " [9.87832427e-01]\n",
      " [8.63007177e-03]\n",
      " [1.03083934e-04]\n",
      " [1.59615956e-05]\n",
      " [1.29459985e-03]\n",
      " [5.79541047e-05]\n",
      " [1.17293710e-03]\n",
      " [9.63646817e-05]\n",
      " [3.55212069e-05]\n",
      " [1.81848809e-04]\n",
      " [9.98563945e-01]\n",
      " [3.73105722e-05]\n",
      " [2.90995260e-04]\n",
      " [2.48817796e-05]\n",
      " [1.53604196e-05]\n",
      " [9.57334936e-01]\n",
      " [9.97625053e-01]\n",
      " [2.03326981e-05]\n",
      " [9.97414351e-01]\n",
      " [4.87290585e-04]\n",
      " [6.68284178e-01]\n",
      " [9.05393856e-04]\n",
      " [5.44772083e-05]\n",
      " [9.86346066e-01]\n",
      " [9.80359733e-01]\n",
      " [3.97627300e-05]\n",
      " [5.21303341e-02]\n",
      " [9.63497005e-05]\n",
      " [9.76741314e-01]\n",
      " [2.40675436e-04]\n",
      " [1.06485514e-03]\n",
      " [5.21736820e-06]\n",
      " [3.99841219e-01]\n",
      " [1.52030421e-04]\n",
      " [5.05839489e-05]\n",
      " [6.48583770e-02]\n",
      " [1.84138902e-02]\n",
      " [2.77942654e-05]\n",
      " [2.12861432e-05]\n",
      " [9.84415472e-01]\n",
      " [6.91320121e-01]\n",
      " [1.65989576e-03]\n",
      " [9.98034298e-01]\n",
      " [2.12890463e-05]\n",
      " [9.98555005e-01]\n",
      " [1.18965603e-04]\n",
      " [1.95924134e-04]\n",
      " [9.87010717e-01]\n",
      " [9.71046209e-01]\n",
      " [7.06034973e-02]\n",
      " [9.97868061e-01]\n",
      " [3.46893212e-05]\n",
      " [9.72633958e-01]\n",
      " [1.73864555e-05]\n",
      " [7.54246712e-02]\n",
      " [1.31901921e-04]\n",
      " [3.19204497e-04]\n",
      " [9.94591117e-01]\n",
      " [1.77106085e-05]\n",
      " [5.07871091e-01]\n",
      " [2.56120431e-04]\n",
      " [9.94342208e-01]\n",
      " [2.65117531e-04]\n",
      " [1.35018126e-04]\n",
      " [3.68189551e-02]\n",
      " [2.34992895e-05]\n",
      " [6.89616501e-01]\n",
      " [1.43060301e-04]\n",
      " [9.97880101e-01]\n",
      " [1.55330199e-04]\n",
      " [4.10695156e-06]\n",
      " [4.92980778e-02]\n",
      " [9.83684286e-02]\n",
      " [3.32332328e-02]\n",
      " [8.06681346e-03]\n",
      " [5.44187985e-02]\n",
      " [1.04431301e-05]\n",
      " [2.14527216e-04]\n",
      " [6.45028922e-05]\n",
      " [9.88099635e-01]\n",
      " [5.58110551e-05]\n",
      " [1.75644556e-04]\n",
      " [2.89886029e-05]\n",
      " [3.75633354e-05]\n",
      " [4.43285608e-05]\n",
      " [6.92393351e-03]\n",
      " [1.25498613e-04]\n",
      " [2.78691659e-05]\n",
      " [3.35986464e-04]\n",
      " [8.20496061e-04]\n",
      " [6.47516936e-05]\n",
      " [2.48817796e-05]\n",
      " [2.40600653e-04]\n",
      " [1.13281676e-04]\n",
      " [1.05611791e-04]\n",
      " [2.40600653e-04]\n",
      " [9.93711352e-01]\n",
      " [9.98954892e-01]\n",
      " [9.85113740e-01]\n",
      " [9.88390446e-01]\n",
      " [1.35629249e-04]\n",
      " [6.00890735e-06]\n",
      " [1.07893907e-03]\n",
      " [3.32225710e-02]\n",
      " [6.03793669e-05]\n",
      " [8.96192968e-01]\n",
      " [9.92255330e-01]\n",
      " [9.66787455e-04]\n",
      " [5.31250407e-06]\n",
      " [3.11273674e-04]\n",
      " [9.93518624e-05]\n",
      " [2.37151573e-04]\n",
      " [7.95457006e-01]\n",
      " [3.91608519e-05]\n",
      " [9.88765532e-05]\n",
      " [2.46445888e-05]\n",
      " [2.15260061e-05]\n",
      " [4.75431643e-02]\n",
      " [3.75856580e-05]\n",
      " [2.57972106e-02]\n",
      " [5.53668251e-05]\n",
      " [2.33306855e-04]\n",
      " [1.05555798e-03]\n",
      " [2.88559683e-03]\n",
      " [6.37347148e-06]\n",
      " [4.83526528e-05]\n",
      " [1.72511674e-04]\n",
      " [1.15100949e-04]\n",
      " [8.72540176e-02]\n",
      " [9.92590904e-01]\n",
      " [5.35338359e-06]\n",
      " [1.03082362e-04]\n",
      " [3.30029055e-04]\n",
      " [3.59795219e-03]\n",
      " [2.48817796e-05]\n",
      " [3.43580439e-04]\n",
      " [2.84415437e-04]\n",
      " [9.92732465e-01]\n",
      " [5.59650971e-06]\n",
      " [3.65348737e-04]\n",
      " [3.49159527e-04]\n",
      " [9.92705286e-01]\n",
      " [9.86983657e-01]\n",
      " [9.78053570e-01]\n",
      " [9.67646956e-01]\n",
      " [3.00468237e-04]\n",
      " [9.81372476e-01]\n",
      " [1.15209515e-03]\n",
      " [4.48793638e-04]\n",
      " [1.42851230e-02]\n",
      " [1.50494861e-05]\n",
      " [9.86585975e-01]\n",
      " [5.25055621e-05]]\n",
      "218/218 [==============================] - 0s 462us/step\n",
      "Accuracy: 65.60%\n"
     ]
    }
   ],
   "source": [
    "#training and testing the model and generating accuracy score.\n",
    "model.fit(data_train[:-1],y_train[:-1], batch_size=128,epochs=5,validation_data=(data_test, y_test), verbose=1,sample_weight=None, initial_epoch=0)\n",
    "yp = model.predict(data_test[:-1], batch_size=32, verbose=1)\n",
    "print(yp)\n",
    "ypreds = np.argmax(yp, axis=1)\n",
    "scores = model.evaluate(data_test[:-1], y_test[:-1], verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "हमारे पास पैसा नहीं है\n",
      "[3, 4, 2, 5, 6, 1]\n",
      "[3 4 2 5 6 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_examples=list(open('C:\\\\Users\\\\vineet\\\\Desktop\\\\test_doc.txt',mode='r',encoding='utf8'))\n",
    "test_examples = [s.strip() for s in test_examples]\n",
    "test_examples_a=np.asarray(test_examples)\n",
    "print (test_examples_a.shape)\n",
    "print(test_examples_a[2])\n",
    "tokenizer = Tokenizer(num_words=None,split=' ',lower=True)\n",
    "tokenizer.fit_on_texts(test_examples_a)\n",
    "integer_sentences_test_examples = tokenizer.texts_to_sequences(test_examples_a)\n",
    "data_test_examples = pad_sequences(integer_sentences_test_examples,padding='post',truncating='post',value=0.,maxlen=30)\n",
    "print(integer_sentences_test_examples[0])\n",
    "print(data_test_examples[0])\n",
    "top_words = 5000\n",
    "max_words = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_examples = sequence.pad_sequences(data_test_examples, maxlen=max_words, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "3/3 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_examples = model.predict(data_test_examples, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.4233853e-01]\n",
      " [3.6825455e-04]\n",
      " [3.5723451e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
